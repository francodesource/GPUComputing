{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivxGuz4MVBBQ"
      },
      "source": [
        "---\n",
        "# **LAB 2 - CUDA Programming Model**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWncoH1Jkuhd"
      },
      "source": [
        "# ‚ñ∂Ô∏è CUDA tools..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUOqJID2kuhd"
      },
      "source": [
        "**NVIDIA System Management Interface (nvidia-smi)**\n",
        "\n",
        "The NVIDIA System Management Interface (**`nvidia-smi`**) is a command line utility, based on top of the NVIDIA Management Library (NVML), intended to aid in the **management** and **monitoring** of NVIDIA GPU devices.\n",
        "\n",
        "This utility allows administrators to query GPU device state and with the appropriate privileges, permits administrators to modify GPU device state.  It is targeted at the TeslaTM, GRIDTM, QuadroTM and Titan X product, though limited support is also available on other NVIDIA GPUs.\n",
        "\n",
        "For more details, please refer to the **`nvidia-smi`** documentation ([doc](http://developer.download.nvidia.com/compute/DCGM/docs/nvidia-smi-367.38.pdf))\n",
        "\n",
        "For information on **Tesla T4** see:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgUgWScpkuhe"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p-5K8K8kuhe"
      },
      "source": [
        "**Numba code used as a CUDA sanity check**:\n",
        "-   Imports Numba, a JIT compiler that accelerates Python code.\n",
        "-\tnumba.cuda provides GPU (CUDA) support using NVIDIA GPUs.\n",
        "\t- ‚úî Confirms NumPy and Numba are installed\n",
        "\t- ‚úî Confirms CUDA drivers are visible\n",
        "\t- ‚úî Confirms GPU compute capability\n",
        "\t- ‚úî Helps debug environment issues before running GPU kernels\n",
        "\n",
        "Probes the system for available CUDA-capable GPUs. Prints:\n",
        "-\tNumber of GPUs\n",
        "-\tGPU names\n",
        "-\tCompute capability\n",
        "-\tDriver/runtime status\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7UsS_AAkuhf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import numba\n",
        "from numba import cuda\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(np.__version__)\n",
        "print(numba.__version__)\n",
        "\n",
        "cuda.detect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKSDGa4wkuhf"
      },
      "outputs": [],
      "source": [
        "# Suppress Numba deprecation and performance warnings\n",
        "from numba.core.errors import NumbaDeprecationWarning, NumbaPerformanceWarning\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
        "warnings.simplefilter('ignore', category=NumbaPerformanceWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbryMNPNkuhf"
      },
      "outputs": [],
      "source": [
        "# Check installed versions of numba and llvmlite\n",
        "!pip list | grep numba\n",
        "!pip list | grep llvmlite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gUDpbz5TZml"
      },
      "source": [
        "# ‚úÖ Blocks and grids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv8Bm5Oobs8g"
      },
      "source": [
        "**Grid 1D**: prints DIMs and IDs of grid, block and thread\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNBkNMrTkuhg"
      },
      "outputs": [],
      "source": [
        "from numba import cuda\n",
        "from wurlitzer import sys_pipes\n",
        "@cuda.jit\n",
        "def checkIndex():\n",
        "    # Absolute position of this thread in the whole grid\n",
        "    gx = cuda.grid(1)          # 1D global index (equivalent to x in a flattened 1D launch)\n",
        "    gstride = cuda.gridsize(1) # total number of threads in the whole grid (1D)\n",
        "\n",
        "    print(  \"threadIdx:\", cuda.threadIdx.x, cuda.threadIdx.y, cuda.threadIdx.z,\n",
        "            \"| blockIdx:\", cuda.blockIdx.x, cuda.blockIdx.y, cuda.blockIdx.z,\n",
        "            \"| blockDim:\", cuda.blockDim.x, cuda.blockDim.y, cuda.blockDim.z,\n",
        "            \"| gridDim:\",  cuda.gridDim.x,  cuda.gridDim.y,  cuda.gridDim.z)\n",
        "\n",
        "    print(  \"cuda.grid(1) =\", gx,\n",
        "            \"| cuda.gridsize(1) =\", gstride)\n",
        "\n",
        "# grid and block definition (1D like dim3 block(4), grid(3))\n",
        "block = 4\n",
        "grid = 3\n",
        "\n",
        "# Print from host\n",
        "print(\"Print from host:\")\n",
        "print(f\"grid.x = {grid}\\t grid.y = 1\\t grid.z = 1\")\n",
        "print(f\"block.x = {block}\\t block.y = 1\\t block.z = 1\\n\")\n",
        "\n",
        "# Print from device\n",
        "print(\"Print from device:\")\n",
        "checkIndex[grid, block]()\n",
        "with sys_pipes():\n",
        "        cuda.synchronize()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-jbxio5Oy_Y"
      },
      "source": [
        "## ‚ÜòÔ∏è TODO..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Hvii50CGGfP"
      },
      "source": [
        "\n",
        "Fibonacci ([Fibonacci-wikipedia](https://it.wikipedia.org/wiki/Successione_di_Fibonacci))\n",
        "$$\n",
        "\\begin{align}\n",
        "s_0 &= 0,\\\\\n",
        "s_1 &= 1,\\\\\n",
        "s_{n}&=s_{{n-1}}+s_{{n-2}},\\quad \\text{(per ogni $n>1$)}\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "\n",
        "üîπ **Device Helper Functions**\n",
        "\n",
        "-   You will need two device functions:\n",
        "    1.  Check if a number is a perfect square\n",
        "    2.  Check if a number belongs to the Fibonacci sequence\n",
        "-   Device functions:\n",
        "    -   run on the GPU\n",
        "    -   can return values are called from kernels\n",
        "\n",
        "```{python}\n",
        "from numba import cuda\n",
        "\n",
        "@cuda.jit(device=True, inline=True)\n",
        "def is_perfect_square(m):\n",
        "    pass\n",
        "\n",
        "@cuda.jit(device=True, inline=True)\n",
        "def is_fibonacci(v):\n",
        "    pass\n",
        "```\n",
        "\n",
        "üîπ **Task Description**\n",
        "\n",
        "-   You must write a CUDA kernel that:\n",
        "    1.  Computes s using thread and block indices\n",
        "    2.  Checks whether s is a Fibonacci number\n",
        "    3.  Write 1 only if s is Fibonacci\n",
        "\n",
        "-   Kernel that checks and prints results:\n",
        "\n",
        "```{python}\n",
        "@cuda.jit\n",
        "def fibonacci_kernel():\n",
        "    pass\n",
        "```\n",
        "\n",
        "üîπ **Kernel Launch Configuration**\n",
        "\n",
        "-   Use a 2D block and a 2D grid:\n",
        "\n",
        "```{python}\n",
        "block = (8, 6)   # blockDim.x, blockDim.y\n",
        "grid  = (3, 5)   # gridDim.x, gridDim.y\n",
        "\n",
        "fibonacci_kernel[grid, block]()\n",
        "cuda.synchronize()\n",
        "```\n",
        "\n",
        "üîπ **Expected Output**\n",
        "\n",
        "-   Only threads for which s is a Fibonacci number write true\n",
        "-   Order of prints is not deterministic\n",
        "-   Output may vary between runs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YA9dRzZtkuhh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numba import cuda\n",
        "import math\n",
        "\n",
        "@cuda.jit(device=True, inline=True)\n",
        "def is_perfect_square(m):\n",
        "    if m < 0: return False\n",
        "    s = int(math.sqrt(m))\n",
        "    return s**2 == m\n",
        "\n",
        "@cuda.jit(device=True, inline=True)\n",
        "def is_fibonacci(v):\n",
        "    vv = 5*v*v\n",
        "    return is_perfect_square(vv - 4) or is_perfect_square(vv + 4)\n",
        "\n",
        "@cuda.jit\n",
        "def fibonacci_kernel_2D(out):\n",
        "    x, y = cuda.grid(2)\n",
        "    #boundary check is needed because we could launch more than the number of thread we need for performance reasons\n",
        "    if x >= out.shape[0] or y >= out.shape[1]:\n",
        "        return\n",
        "\n",
        "    # v = x + y\n",
        "    v = abs(x - y)\n",
        "    out[x, y] = 1 if is_fibonacci(v) else 0\n",
        "\n",
        "# ----------------------\n",
        "#  kernel launch\n",
        "# ----------------------\n",
        "\n",
        "n = 200  # matrix size n x n\n",
        "block = (8, 8)\n",
        "grid = ( (n + block[0] - 1) // block[0], (n + block[1] - 1) // block[1] )\n",
        "\n",
        "x = np.zeros((n, n), dtype=np.int32)\n",
        "d_x = cuda.device_array_like(x)\n",
        "fibonacci_kernel_2D[grid, block](d_x)\n",
        "\n",
        "cuda.synchronize()\n",
        "x = d_x.copy_to_host()\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPZDSMMZkuhh"
      },
      "outputs": [],
      "source": [
        "# printing the matrix as an image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(x, cmap='gray')\n",
        "plt.axis('off')\n",
        "#plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VmTF-mKkuhi"
      },
      "source": [
        "## ‚û°Ô∏è Solution..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RNlS5U0adAk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numba import cuda\n",
        "import math\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# --- device helpers ---\n",
        "@cuda.jit(device=True, inline=True)\n",
        "def is_perfect_square(m):\n",
        "    if m < 0:\n",
        "        return False\n",
        "    r = int(math.sqrt(m))\n",
        "    return r * r == m\n",
        "\n",
        "@cuda.jit(device=True, inline=True)\n",
        "def is_fibonacci(v):\n",
        "    if v < 0:\n",
        "        return False\n",
        "    vv = np.int64(v)\n",
        "    t1 = np.int64(5) * vv * vv + np.int64(4)\n",
        "    t2 = np.int64(5) * vv * vv - np.int64(4)\n",
        "    return is_perfect_square(t1) or is_perfect_square(t2)\n",
        "\n",
        "# --- kernel ---\n",
        "@cuda.jit\n",
        "def fibonacci_kernel_2D(out):\n",
        "    x, y = cuda.grid(2)  # 2D global thread indices\n",
        "\n",
        "    # boundary check\n",
        "    if x >= out.shape[0] or y >= out.shape[1]:\n",
        "        return\n",
        "\n",
        "    # check Fibonacci\n",
        "    if is_fibonacci(abs(x-y)):\n",
        "        out[x, y] = 1\n",
        "\n",
        "\n",
        "# ----------------------\n",
        "#  kernel launch\n",
        "# ----------------------\n",
        "\n",
        "n = 200  # matrix size n x n\n",
        "\n",
        "# choose block and grid dimensions\n",
        "block = (8, 8)   # blockDim.x, blockDim.y\n",
        "grid  = ((n+block[0]-1) // block[0], (n+block[1]-1) // block[1])   # gridDim.x, gridDim.y\n",
        "\n",
        "# allocate output array on device\n",
        "out = np.zeros((n,n), dtype=np.int32)\n",
        "out_d = cuda.to_device(out)\n",
        "\n",
        "# launch kernel\n",
        "fibonacci_kernel_2D[grid, block](out_d)\n",
        "cuda.synchronize()\n",
        "\n",
        "# copy result back to host\n",
        "out_d.copy_to_host(out)\n",
        "\n",
        "# ----------------------\n",
        "#  visualize result\n",
        "# ----------------------\n",
        "# create heatmap\n",
        "\n",
        "\n",
        "fig = go.Figure(\n",
        "    go.Heatmap(\n",
        "        z=out,\n",
        "        colorscale=\"Gray\",\n",
        "        showscale=False\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Binary Fibonacci Image\",\n",
        "    width=1000,\n",
        "    height=1000,\n",
        "    xaxis=dict(showticklabels=False),\n",
        "    yaxis=dict(showticklabels=False),\n",
        "    yaxis_autorange=\"reversed\"\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neXhTBlkk7Oz"
      },
      "source": [
        "# ‚úÖ Image flip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZZTbmBBGDf9"
      },
      "source": [
        "**Visualizza immagine in python**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qTJDjRkDk_2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fqxxxaUkuhi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "img = Image.open(\"./lab2/imgs/dog.bmp\")\n",
        "img_mat = np.array(img).astype(np.uint8)\n",
        "H, W = img_mat.shape[0], img_mat.shape[1]\n",
        "print(f\"Image size: {W} x {H}\")\n",
        "img\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvOoerr-DqRy"
      },
      "source": [
        "Kernels..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayiBCTVekuhj"
      },
      "outputs": [],
      "source": [
        "from numba import cuda\n",
        "\n",
        "\n",
        "@cuda.jit\n",
        "def flip_horizontal(img, out):\n",
        "    \"\"\" Flip image horizontally\n",
        "\n",
        "        Params:\n",
        "        ----------\n",
        "            img : array_like\n",
        "                Input image (H, W, 3)\n",
        "            out : array_like\n",
        "                Output image (H, W, 3)\n",
        "    \"\"\"\n",
        "    y, x = cuda.grid(2)\n",
        "\n",
        "    H, W, C = img.shape\n",
        "\n",
        "    if y < H and x < W:\n",
        "        if C >= 1:\n",
        "            out[y, x, 0] = img[y, W - 1 - x, 0]\n",
        "        if C >= 2:\n",
        "            out[y, x, 1] = img[y, W - 1 - x, 1]\n",
        "        if C >= 3:\n",
        "            out[y, x, 2] = img[y, W - 1 - x, 2]\n",
        "\n",
        "@cuda.jit\n",
        "def flip_vertical(img, out):\n",
        "    \"\"\" Flip image vertically\n",
        "\n",
        "        Params:\n",
        "        ----------\n",
        "            img : array_like\n",
        "                Input image (H, W, 3)\n",
        "            out : array_like\n",
        "                Output image (H, W, 3)\n",
        "    \"\"\"\n",
        "    y, x = cuda.grid(2)\n",
        "    H, W, C = img.shape\n",
        "    if y < H and x < W:\n",
        "        for c in range(C):\n",
        "            out[y, x, c] = img[H - 1 - y, x, c]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yneLjqyTkuhj"
      },
      "source": [
        "Horizontal flip..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LYAHwQHkuhj"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# Device memory\n",
        "d_img = cuda.to_device(img_mat)\n",
        "d_out = cuda.device_array_like(img_mat)\n",
        "\n",
        "# Launch configuration\n",
        "threads_per_block = (16, 16)\n",
        "blocks_per_grid = (\n",
        "    (H + threads_per_block[0] - 1) // threads_per_block[0],\n",
        "    (W + threads_per_block[1] - 1) // threads_per_block[1],\n",
        ")\n",
        "\n",
        "# Kernel launch\n",
        "t0 = time.perf_counter()\n",
        "flip_horizontal[blocks_per_grid, threads_per_block](d_img, d_out)\n",
        "cuda.synchronize()\n",
        "t1 = time.perf_counter()\n",
        "print(f\"Kernel time: {(t1 - t0)*1e3:.3f} ms\")\n",
        "\n",
        "# cpu code for verification\n",
        "tic = time.time()\n",
        "imgHFlip_cpu = np.flip(img, axis=1)\n",
        "toc = time.time()\n",
        "print(f\"CPU time: {(toc - tic)*1e3:.3f} ms\")\n",
        "\n",
        "# print speedup\n",
        "print(f\"Speedup: {(toc - tic)/(t1 - t0):.2f}x\")\n",
        "\n",
        "# Copy back\n",
        "out = d_out.copy_to_host()\n",
        "imgHFlip = Image.fromarray(out)\n",
        "imgHFlip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOOK0arGkuhj"
      },
      "source": [
        "Vertical flip..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_SCPy3bkuhj"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# Device memory\n",
        "d_img = cuda.to_device(img_mat)\n",
        "d_out = cuda.device_array_like(img_mat)\n",
        "# Launch configuration\n",
        "threads_per_block = (16, 16)\n",
        "blocks_per_grid = (\n",
        "    (H + threads_per_block[0] - 1) // threads_per_block[0],\n",
        "    (W + threads_per_block[1] - 1) // threads_per_block[1],\n",
        ")\n",
        "\n",
        "# Kernel launch\n",
        "t0 = time.perf_counter()\n",
        "flip_vertical[blocks_per_grid, threads_per_block](d_img, d_out)\n",
        "cuda.synchronize()\n",
        "t1 = time.perf_counter()\n",
        "print(f\"Kernel time: {(t1 - t0)*1e3:.3f} ms\")\n",
        "\n",
        "# cpu code for verification\n",
        "tic = time.time()\n",
        "imgVFlip_cpu = np.flip(img, axis=0)\n",
        "toc = time.time()\n",
        "print(f\"CPU time: {(toc - tic)*1e3:.3f} ms\")\n",
        "\n",
        "# print speedup\n",
        "print(f\"Speedup: {(toc - tic)/(t1 - t0):.2f}x\")\n",
        "\n",
        "# Copy back\n",
        "out = d_out.copy_to_host()\n",
        "imgVFlip = Image.fromarray(out)\n",
        "imgVFlip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oEZ69DPMEPK"
      },
      "source": [
        "# ‚úÖ Image blurring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUxpgYxEkuhk"
      },
      "source": [
        "## ‚ÜòÔ∏è TODO..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ4tJ1o0kuhk"
      },
      "source": [
        "üîπ **Exercise Tasks**\n",
        "\n",
        "1. Write a Numba CUDA kernel `blur_box(img, out, mask_size)`\n",
        "2. Compute `(y, x)` using `cuda.grid(2)`\n",
        "3. For each output pixel:\n",
        "   - loop over neighborhood offsets\n",
        "   - check boundaries\n",
        "   - accumulate channels\n",
        "   - divide by `numPixels`\n",
        "4. Launch with a 2D configuration, e.g. `(16,16)` threads per block\n",
        "5. Validate correctness vs a CPU implementation on a small image\n",
        "\n",
        "\n",
        "üîπ  **Starter Code (Fill the TODOs)**\n",
        "\n",
        "\n",
        "```{python}\n",
        "#| eval: false\n",
        "import numpy as np\n",
        "from numba import cuda\n",
        "\n",
        "@cuda.jit\n",
        "def blur_box(img, out, mask_size):\n",
        "    \n",
        "    # TODO: bounds check\n",
        "\n",
        "    # TODO: initialize accumulators (float)\n",
        "    \n",
        "    # TODO: neighborhood loops\n",
        "    \n",
        "    # TODO: write averaged pixel (cast back to dtype)\n",
        "    \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSDjzxywkuhk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "img = Image.open(\"../images/mandelbrot.png\")\n",
        "img_mat = np.array(img).astype(np.uint8)\n",
        "H, W = img_mat.shape[0], img_mat.shape[1]\n",
        "print(f\"Image size: {W} x {H}\")\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltei6uxkkuhk"
      },
      "outputs": [],
      "source": [
        "from PIL import ImageFilter\n",
        "import time\n",
        "\n",
        "# Apply a blur filter to the image\n",
        "tic = time.time()\n",
        "blurred_image = img.filter(ImageFilter.BoxBlur(radius=10))\n",
        "toc = time.time()\n",
        "print(f\"PIL BoxBlur time: {(toc - tic)*1e3:.3f} ms\")\n",
        "# Display the blurred mage\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "F9PmBZql0ow4",
        "5gUDpbz5TZml",
        "v1aLRuwryuL-",
        "neXhTBlkk7Oz",
        "VvOoerr-DqRy",
        "rlA0oQTE3SqN",
        "8oEZ69DPMEPK"
      ],
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}