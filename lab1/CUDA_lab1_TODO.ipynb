{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivxGuz4MVBBQ"
   },
   "source": [
    "---\n",
    "# **LAB 1 - Intro to Numba**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YGa6hXkx77o"
   },
   "source": [
    "# ‚ñ∂Ô∏è Google Colaboratory (colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-lZoo4TstJn"
   },
   "source": [
    "[Colaboratory](https://research.google.com/colaboratory/faq.html) (or Colab) is a **free research tool** from *Google* for machine learning education and research built on top of [Jupyter Notebook](https://jupyter.org/). It requires no setup and runs entirely in the **cloud**. In Google Colab you can write, execute, save and share your Jupiter Notebooks. You access powerful computing resources like **TPUs** and **GPUs** all for free through your browser. All major Python libraries like **Tensorflow**, **Scikit-learn**, **PyTorch**, **Pandas**, etc. are pre-installed. Google Colab requires no configuration, you only need a **Google Account** and then you are good to go. Your notebooks are stored in your **Google Drive**, or can be loaded from **GitHub**. Colab notebooks can be shared just as you would with Google Docs or Sheets. Simply click the Share button at the top right of any Colab notebook, or follow these Google Drive file sharing instructions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZvWtrdMfxQD8"
   },
   "source": [
    "### Notebook rules\n",
    "\n",
    "Some basic notebook rules:\n",
    "\n",
    "\n",
    "1.   Click inside a cell with code and press SHIFT+ENTER (or click \"PLAY\" button) to execute it.\n",
    "2.   Re-executing a cell will reset it (any input will be lost).\n",
    "3.   Execute cells TOP TO BOTTOM.\n",
    "5. Notebooks are saved to your Google Drive\n",
    "6. Mount your Google Drive to have a direct access from a notebook to the files stored in the drive (this includes Team Drives).\n",
    "7. If using Colab's virtual storage only, all the uploaded/stored files will get deleted when a runtime is recycled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulev4sV3wc-T"
   },
   "source": [
    "### Shell commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fS67zRIavQtS"
   },
   "source": [
    "The command `uname` displays the information about the system.\n",
    "\n",
    "* **-a option:** It prints all the system information in the following order: Kernel name, network node hostname,\n",
    "kernel release date, kernel version, machine hardware name, hardware platform, operating system\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PT7Umr53u2Qz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux 588a60014de5 6.6.105+ #1 SMP Thu Oct  2 10:42:05 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux\n",
      "DISTRIB_ID=Ubuntu\n",
      "DISTRIB_RELEASE=22.04\n",
      "DISTRIB_CODENAME=jammy\n",
      "DISTRIB_DESCRIPTION=\"Ubuntu 22.04.4 LTS\"\n",
      "PRETTY_NAME=\"Ubuntu 22.04.4 LTS\"\n",
      "NAME=\"Ubuntu\"\n",
      "VERSION_ID=\"22.04\"\n",
      "VERSION=\"22.04.4 LTS (Jammy Jellyfish)\"\n",
      "VERSION_CODENAME=jammy\n",
      "ID=ubuntu\n",
      "ID_LIKE=debian\n",
      "HOME_URL=\"https://www.ubuntu.com/\"\n",
      "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
      "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
      "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
      "UBUNTU_CODENAME=jammy\n"
     ]
    }
   ],
   "source": [
    "!uname -a && cat /etc/*release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "i1h8YWW1RzEN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "j_fkW3x5hu85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16\n",
      "drwxr-xr-x 1 root root 4096 Dec  9 14:41 .\n",
      "drwxr-xr-x 1 root root 4096 Jan 16 13:04 ..\n",
      "drwxr-xr-x 4 root root 4096 Dec  9 14:41 .config\n",
      "drwxr-xr-x 1 root root 4096 Dec  9 14:42 sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcg1GyK5srek"
   },
   "source": [
    "### Set up Google Drive...\n",
    "\n",
    "That snippet is used in **Google Colab** to mount your **Google Drive**.\n",
    "\n",
    "- Imports the **Colab utility** to access Google Drive\n",
    "- Mounts your Drive at the **path**:\n",
    "`/content/drive/MyDrive/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3RDr9PREJBnA"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9PmBZql0ow4"
   },
   "source": [
    "# ‚ñ∂Ô∏è CUDA tools..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTRXba1Msgq2"
   },
   "source": [
    "**NVIDIA System Management Interface (nvidia-smi)**\n",
    "\n",
    "The NVIDIA System Management Interface (**`nvidia-smi`**) is a command line utility, based on top of the NVIDIA Management Library (NVML), intended to aid in the **management** and **monitoring** of NVIDIA GPU devices.\n",
    "\n",
    "This utility allows administrators to query GPU device state and with the appropriate privileges, permits administrators to modify GPU device state.  It is targeted at the TeslaTM, GRIDTM, QuadroTM and Titan X product, though limited support is also available on other NVIDIA GPUs.\n",
    "\n",
    "For more details, please refer to the **`nvidia-smi`** documentation ([doc](http://developer.download.nvidia.com/compute/DCGM/docs/nvidia-smi-367.38.pdf))\n",
    "\n",
    "For information on **Tesla T4** see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NlXMCnBVBkeE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 16 13:09:02 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   54C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numba code used as a CUDA sanity check**:\n",
    "-   Imports Numba, a JIT compiler that accelerates Python code.\n",
    "-\tnumba.cuda provides GPU (CUDA) support using NVIDIA GPUs.\n",
    "\t- ‚úî Confirms NumPy and Numba are installed\n",
    "\t- ‚úî Confirms CUDA drivers are visible\n",
    "\t- ‚úî Confirms GPU compute capability\n",
    "\t- ‚úî Helps debug environment issues before running GPU kernels\n",
    "\n",
    "Probes the system for available CUDA-capable GPUs. Prints:\n",
    "-\tNumber of GPUs\n",
    "-\tGPU names\n",
    "-\tCompute capability\n",
    "-\tDriver/runtime status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.5\n",
      "0.63.1\n",
      "Found 1 CUDA devices\n",
      "id 0    b'NVIDIA GeForce MX330'                              [SUPPORTED]\n",
      "                      Compute Capability: 6.1\n",
      "                           PCI Device ID: 0\n",
      "                              PCI Bus ID: 59\n",
      "                                    UUID: GPU-01144e3b-2add-f806-624d-45fa97ef273a\n",
      "                                Watchdog: Enabled\n",
      "                            Compute Mode: WDDM\n",
      "             FP32/FP64 Performance Ratio: 32\n",
      "Summary:\n",
      "\t1/1 devices are supported\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "from numba import cuda\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(np.__version__)\n",
    "print(numba.__version__)\n",
    "\n",
    "cuda.detect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mB94Ce6kViOj"
   },
   "source": [
    "# ‚úÖ Hello World!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIlUaQYgdooS"
   },
   "source": [
    "**My first CUDA program: HelloFromGPU!**\n",
    "\n",
    "CUDA kernel for Hello world..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "\n",
    "@cuda.jit\n",
    "def hello_kernel():\n",
    "    print(\"Hello from GPU!\")\n",
    "    \n",
    "# launch with 1 block, 10 thread\n",
    "hello_kernel[1, 10]()    # type: ignore\n",
    "cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VJXO5U8JSGz"
   },
   "source": [
    "# ‚úÖ Parallel vector sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2.] [2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "@cuda.jit\n",
    "def add_arrays_cuda(a, b, c):\n",
    "    i = cuda.grid(1)\n",
    "    if i < c.size:\n",
    "        c[i] = a[i] + b[i]\n",
    "\n",
    "# Example\n",
    "n = 1000    # size of arrays = number of threads\n",
    "a = np.ones(n, dtype=np.float32)\n",
    "b = np.ones(n, dtype=np.float32)\n",
    "\n",
    "d_a = cuda.to_device(a)\n",
    "d_b = cuda.to_device(b)\n",
    "d_c = cuda.device_array_like(a)\n",
    "\n",
    "add_arrays_cuda[1, n](d_a, d_b, d_c)\n",
    "cuda.synchronize()\n",
    "\n",
    "c = d_c.copy_to_host()\n",
    "print(c[0:10], c[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ku--dgMncvGP"
   },
   "source": [
    "## ‚ÜòÔ∏è TODO..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check Fibonacci Membership** \n",
    "\n",
    "üîπ **Exercise Goal**\n",
    "\n",
    "-   Given a vector $x$ of integers, build a CUDA kernel (Numba) that produces a vector $y$ such that:\n",
    "\n",
    "$$\n",
    "y_i =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } x_i \\text{ is a Fibonacci number} \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "üîπ **Input** \n",
    "\n",
    "- `x`: 1D array of integers (e.g., `np.int32`)\n",
    "- `n = x.size`\n",
    "\n",
    "üîπ **Output**\n",
    "\n",
    "- `y`: 1D array of `np.uint8` or `np.int32`\n",
    "- Same length as `x`\n",
    "\n",
    "\n",
    "üîπ **Constraints**\n",
    "\n",
    "- One GPU thread handles one element:\n",
    "  $$\n",
    "  i = \\text{cuda.grid}(1)\n",
    "  $$\n",
    "- Must include a bounds check:\n",
    "  $$\n",
    "  i < n\n",
    "  $$\n",
    "- Avoid Python objects and dynamic allocation inside the kernel\n",
    "\n",
    "\n",
    "üîπ **A classic property:**\n",
    "\n",
    "> An integer $v \\ge 0$ is Fibonacci **iff** one of these is a perfect square:\n",
    "$$\n",
    "5v^2 + 4 \\quad \\text{or} \\quad 5v^2 - 4\n",
    "$$\n",
    "\n",
    "\n",
    "üîπ **Your Tasks**\n",
    "\n",
    "1. Write a device function:\n",
    "   - `is_perfect_square(m) -> bool`\n",
    "\n",
    "2. Write a device function:\n",
    "   - `is_fib(v) -> bool`\n",
    "\n",
    "3. Write a kernel:\n",
    "   - `fib_mask(x, y)` that sets `y[i] = 1` if `x[i]` is Fibonacci else `0`\n",
    "\n",
    "4. Write host code to:\n",
    "   - allocate/copy arrays to GPU\n",
    "   - launch the kernel\n",
    "   - copy results back and validate\n",
    "\n",
    "üîπ **Expected result** \n",
    "-    for the first $n = 1000$ integers: [0,   1,   2,   3,   5,   8,  13,  21,  34,  55,  89, 144, 233, 377, 610, 987]\n",
    "\n",
    "üîπ **Skeleton Code (Fill the TODOs)**\n",
    "\n",
    "```{python}\n",
    "    #| echo: true\n",
    "    import numpy as np\n",
    "    from numba import cuda\n",
    "    import math\n",
    "\n",
    "    @cuda.jit\n",
    "    def fib_numbers(x,y):\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    # input data\n",
    "        # TODO\n",
    "\n",
    "    # GPU memory allocation\n",
    "        # TODO\n",
    "\n",
    "    # Kernel launch\n",
    "        # TODO\n",
    "\n",
    "    # Copy back results & print indexes of Fibonacci numbers\n",
    "        # TODO\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "@cuda.jit(device=True, inline=True)\n",
    "def is_perfect_square(m) -> bool:\n",
    "    if m < 0:\n",
    "        return False\n",
    "    s = int(math.sqrt(m))\n",
    "    return s*s == m\n",
    "\n",
    "@cuda.jit(device=True, inline=True)\n",
    "def is_fib(v) -> bool:\n",
    "    vv = 5*v**2\n",
    "    return is_perfect_square(vv - 4) or is_perfect_square(vv + 4)\n",
    "\n",
    "# kernel\n",
    "@cuda.jit\n",
    "def fib_numbers(x, y):\n",
    "    id = cuda.grid(1)\n",
    "\n",
    "    if id < y.size and is_fib(x[id]): \n",
    "        y[id] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  0,   1,   2,   3,   5,   8,  13,  21,  34,  55,  89, 144, 233,\n",
      "       377, 610, 987]),)\n"
     ]
    }
   ],
   "source": [
    "n = 1024\n",
    "x = np.arange(n, dtype=np.int32)\n",
    "d_x = cuda.to_device(x)\n",
    "d_y = cuda.device_array_like(d_x)\n",
    "\n",
    "fib_numbers[1, n](d_x, d_y)\n",
    "cuda.synchronize()\n",
    "y = d_y.copy_to_host()\n",
    "\n",
    "print(y.nonzero())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "9YGa6hXkx77o",
    "F9PmBZql0ow4",
    "227eLdP5csN1",
    "4bll8pe7Fj3y"
   ],
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1WU0UNEexcE6n3hufdRUgHmlSvXnClfr4",
     "timestamp": 1677494778770
    },
    {
     "file_id": "1IFQanBdBBUzqheWXiloaVlYrS_p2zjrL",
     "timestamp": 1677229457617
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
