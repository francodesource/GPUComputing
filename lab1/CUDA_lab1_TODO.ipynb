{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivxGuz4MVBBQ"
   },
   "source": [
    "---\n",
    "# **LAB 1 - Intro to Numba**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YGa6hXkx77o"
   },
   "source": [
    "# ‚ñ∂Ô∏è Google Colaboratory (colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-lZoo4TstJn"
   },
   "source": [
    "[Colaboratory](https://research.google.com/colaboratory/faq.html) (or Colab) is a **free research tool** from *Google* for machine learning education and research built on top of [Jupyter Notebook](https://jupyter.org/). It requires no setup and runs entirely in the **cloud**. In Google Colab you can write, execute, save and share your Jupiter Notebooks. You access powerful computing resources like **TPUs** and **GPUs** all for free through your browser. All major Python libraries like **Tensorflow**, **Scikit-learn**, **PyTorch**, **Pandas**, etc. are pre-installed. Google Colab requires no configuration, you only need a **Google Account** and then you are good to go. Your notebooks are stored in your **Google Drive**, or can be loaded from **GitHub**. Colab notebooks can be shared just as you would with Google Docs or Sheets. Simply click the Share button at the top right of any Colab notebook, or follow these Google Drive file sharing instructions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZvWtrdMfxQD8"
   },
   "source": [
    "### Notebook rules\n",
    "\n",
    "Some basic notebook rules:\n",
    "\n",
    "\n",
    "1.   Click inside a cell with code and press SHIFT+ENTER (or click \"PLAY\" button) to execute it.\n",
    "2.   Re-executing a cell will reset it (any input will be lost).\n",
    "3.   Execute cells TOP TO BOTTOM.\n",
    "5. Notebooks are saved to your Google Drive\n",
    "6. Mount your Google Drive to have a direct access from a notebook to the files stored in the drive (this includes Team Drives).\n",
    "7. If using Colab's virtual storage only, all the uploaded/stored files will get deleted when a runtime is recycled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulev4sV3wc-T"
   },
   "source": [
    "### Shell commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fS67zRIavQtS"
   },
   "source": [
    "The command `uname` displays the information about the system.\n",
    "\n",
    "* **-a option:** It prints all the system information in the following order: Kernel name, network node hostname,\n",
    "kernel release date, kernel version, machine hardware name, hardware platform, operating system\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PT7Umr53u2Qz"
   },
   "outputs": [],
   "source": [
    "!uname -a && cat /etc/*release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1h8YWW1RzEN"
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_fkW3x5hu85"
   },
   "outputs": [],
   "source": [
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcg1GyK5srek"
   },
   "source": [
    "### Set up Google Drive...\n",
    "\n",
    "That snippet is used in **Google Colab** to mount your **Google Drive**.\n",
    "\n",
    "- Imports the **Colab utility** to access Google Drive\n",
    "- Mounts your Drive at the **path**:\n",
    "`/content/drive/MyDrive/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3RDr9PREJBnA"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9PmBZql0ow4"
   },
   "source": [
    "# ‚ñ∂Ô∏è CUDA tools..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTRXba1Msgq2"
   },
   "source": [
    "**NVIDIA System Management Interface (nvidia-smi)**\n",
    "\n",
    "The NVIDIA System Management Interface (**`nvidia-smi`**) is a command line utility, based on top of the NVIDIA Management Library (NVML), intended to aid in the **management** and **monitoring** of NVIDIA GPU devices.\n",
    "\n",
    "This utility allows administrators to query GPU device state and with the appropriate privileges, permits administrators to modify GPU device state.  It is targeted at the TeslaTM, GRIDTM, QuadroTM and Titan X product, though limited support is also available on other NVIDIA GPUs.\n",
    "\n",
    "For more details, please refer to the **`nvidia-smi`** documentation ([doc](http://developer.download.nvidia.com/compute/DCGM/docs/nvidia-smi-367.38.pdf))\n",
    "\n",
    "For information on **Tesla T4** see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NlXMCnBVBkeE"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numba code used as a CUDA sanity check**:\n",
    "-   Imports Numba, a JIT compiler that accelerates Python code.\n",
    "-\tnumba.cuda provides GPU (CUDA) support using NVIDIA GPUs.\n",
    "\t- ‚úî Confirms NumPy and Numba are installed\n",
    "\t- ‚úî Confirms CUDA drivers are visible\n",
    "\t- ‚úî Confirms GPU compute capability\n",
    "\t- ‚úî Helps debug environment issues before running GPU kernels\n",
    "\n",
    "Probes the system for available CUDA-capable GPUs. Prints:\n",
    "-\tNumber of GPUs\n",
    "-\tGPU names\n",
    "-\tCompute capability\n",
    "-\tDriver/runtime status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "from numba import cuda\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(np.__version__)\n",
    "print(numba.__version__)\n",
    "\n",
    "cuda.detect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mB94Ce6kViOj"
   },
   "source": [
    "# ‚úÖ Hello World!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIlUaQYgdooS"
   },
   "source": [
    "**My first CUDA program: HelloFromGPU!**\n",
    "\n",
    "CUDA kernel for Hello world..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "\n",
    "@cuda.jit\n",
    "def hello_kernel():\n",
    "    print(\"Hello from GPU!\")\n",
    "    \n",
    "# launch with 1 block, 10 thread\n",
    "hello_kernel[1, 10]()    # type: ignore\n",
    "cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VJXO5U8JSGz"
   },
   "source": [
    "# ‚úÖ Parallel vector sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "@cuda.jit\n",
    "def add_arrays_cuda(a, b, c):\n",
    "    i = cuda.grid(1)\n",
    "    if i < c.size:\n",
    "        c[i] = a[i] + b[i]\n",
    "\n",
    "# Example\n",
    "n = 1000    # size of arrays = number of threads\n",
    "a = np.ones(n, dtype=np.float32)\n",
    "b = np.ones(n, dtype=np.float32)\n",
    "\n",
    "d_a = cuda.to_device(a)\n",
    "d_b = cuda.to_device(b)\n",
    "d_c = cuda.device_array_like(a)\n",
    "\n",
    "add_arrays_cuda[1, n](d_a, d_b, d_c)\n",
    "cuda.synchronize()\n",
    "\n",
    "c = d_c.copy_to_host()\n",
    "print(c[0:10], c[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ku--dgMncvGP"
   },
   "source": [
    "## ‚ÜòÔ∏è TODO..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check Fibonacci Membership** \n",
    "\n",
    "üîπ **Exercise Goal**\n",
    "\n",
    "-   Given a vector $x$ of integers, build a CUDA kernel (Numba) that produces a vector $y$ such that:\n",
    "\n",
    "$$\n",
    "y_i =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } x_i \\text{ is a Fibonacci number} \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "üîπ **Input** \n",
    "\n",
    "- `x`: 1D array of integers (e.g., `np.int32`)\n",
    "- `n = x.size`\n",
    "\n",
    "üîπ **Output**\n",
    "\n",
    "- `y`: 1D array of `np.uint8` or `np.int32`\n",
    "- Same length as `x`\n",
    "\n",
    "\n",
    "üîπ **Constraints**\n",
    "\n",
    "- One GPU thread handles one element:\n",
    "  $$\n",
    "  i = \\text{cuda.grid}(1)\n",
    "  $$\n",
    "- Must include a bounds check:\n",
    "  $$\n",
    "  i < n\n",
    "  $$\n",
    "- Avoid Python objects and dynamic allocation inside the kernel\n",
    "\n",
    "\n",
    "üîπ **A classic property:**\n",
    "\n",
    "> An integer $v \\ge 0$ is Fibonacci **iff** one of these is a perfect square:\n",
    "$$\n",
    "5v^2 + 4 \\quad \\text{or} \\quad 5v^2 - 4\n",
    "$$\n",
    "\n",
    "\n",
    "üîπ **Your Tasks**\n",
    "\n",
    "1. Write a device function:\n",
    "   - `is_perfect_square(m) -> bool`\n",
    "\n",
    "2. Write a device function:\n",
    "   - `is_fib(v) -> bool`\n",
    "\n",
    "3. Write a kernel:\n",
    "   - `fib_mask(x, y)` that sets `y[i] = 1` if `x[i]` is Fibonacci else `0`\n",
    "\n",
    "4. Write host code to:\n",
    "   - allocate/copy arrays to GPU\n",
    "   - launch the kernel\n",
    "   - copy results back and validate\n",
    "\n",
    "üîπ **Expected result** \n",
    "-    for the first $n = 1000$ integers: [0,   1,   2,   3,   5,   8,  13,  21,  34,  55,  89, 144, 233, 377, 610, 987]\n",
    "\n",
    "üîπ **Skeleton Code (Fill the TODOs)**\n",
    "\n",
    "```{python}\n",
    "    #| echo: true\n",
    "    import numpy as np\n",
    "    from numba import cuda\n",
    "    import math\n",
    "\n",
    "    @cuda.jit\n",
    "    def fib_numbers(x,y):\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    # input data\n",
    "        # TODO\n",
    "\n",
    "    # GPU memory allocation\n",
    "        # TODO\n",
    "\n",
    "    # Kernel launch\n",
    "        # TODO\n",
    "\n",
    "    # Copy back results & print indexes of Fibonacci numbers\n",
    "        # TODO\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "9YGa6hXkx77o",
    "F9PmBZql0ow4",
    "227eLdP5csN1",
    "4bll8pe7Fj3y"
   ],
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1WU0UNEexcE6n3hufdRUgHmlSvXnClfr4",
     "timestamp": 1677494778770
    },
    {
     "file_id": "1IFQanBdBBUzqheWXiloaVlYrS_p2zjrL",
     "timestamp": 1677229457617
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
